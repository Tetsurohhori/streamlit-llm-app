import streamlit as st
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# å°‚é–€å®¶ã®ç¨®é¡ã¨ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å®šç¾©
EXPERT_TYPES = {
    "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å°‚é–€å®¶": "ã‚ãªãŸã¯ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®å°‚é–€å®¶ã§ã™ã€‚ã‚³ãƒ¼ãƒ‰ã®æ›¸ãæ–¹ã€ãƒ‡ãƒãƒƒã‚°ã€ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã«ã¤ã„ã¦ã€ã‚ã‹ã‚Šã‚„ã™ãä¸å¯§ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
    "ãƒ“ã‚¸ãƒã‚¹ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ": "ã‚ãªãŸã¯ãƒ“ã‚¸ãƒã‚¹ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã®å°‚é–€å®¶ã§ã™ã€‚çµŒå–¶æˆ¦ç•¥ã€ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã€æ¥­å‹™æ”¹å–„ã«ã¤ã„ã¦ã€å®Ÿè·µçš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚",
    "å¥åº·ãƒ»æ „é¤Šã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼": "ã‚ãªãŸã¯å¥åº·ã¨æ „é¤Šã®å°‚é–€å®¶ã§ã™ã€‚å¥åº·çš„ãªç”Ÿæ´»ç¿’æ…£ã€æ „é¤Šãƒãƒ©ãƒ³ã‚¹ã€é‹å‹•ã«ã¤ã„ã¦ã€ç§‘å­¦çš„æ ¹æ‹ ã«åŸºã¥ã„ãŸã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚",
    "èªå­¦æ•™å¸«": "ã‚ãªãŸã¯èªå­¦æ•™è‚²ã®å°‚é–€å®¶ã§ã™ã€‚è¨€èªå­¦ç¿’ã®ã‚³ãƒ„ã€æ–‡æ³•ã€è¡¨ç¾æ–¹æ³•ã«ã¤ã„ã¦ã€ã‚ã‹ã‚Šã‚„ã™ãæ•™ãˆã¦ãã ã•ã„ã€‚"
}

def get_llm_response(user_input: str, expert_type: str) -> str:
    """
    LLMã‹ã‚‰ã®å›ç­”ã‚’å–å¾—ã™ã‚‹é–¢æ•°
    
    Args:
        user_input (str): ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
        expert_type (str): å°‚é–€å®¶ã®ç¨®é¡
    
    Returns:
        str: LLMã‹ã‚‰ã®å›ç­”
    """
    # ChatOpenAIã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ä½œæˆ
    chat = ChatOpenAI(
        model="gpt-3.5-turbo",
        temperature=0.7,
        openai_api_key=os.getenv("OPENAI_API_KEY")
    )
    
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ä½œæˆ
    system_message = SystemMessage(content=EXPERT_TYPES[expert_type])
    human_message = HumanMessage(content=user_input)
    
    # LLMã«å•ã„åˆã‚ã›
    response = chat.invoke([system_message, human_message])
    
    return response.content

# ã‚¢ãƒ—ãƒªç”»é¢ã®æ§‹ç¯‰
# Streamlitã‚¢ãƒ—ãƒªã®ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜
st.title("ğŸ¤– AIå°‚é–€å®¶ç›¸è«‡ã‚¢ãƒ—ãƒª")

st.markdown("""
### ğŸ“‹ ã‚¢ãƒ—ãƒªã®æ¦‚è¦
ã“ã®ã‚¢ãƒ—ãƒªã§ã¯ã€æ§˜ã€…ãªåˆ†é‡ã®å°‚é–€å®¶AIã«è³ªå•ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
å°‚é–€å®¶ã‚’é¸æŠã—ã¦ã€è³ªå•ã‚’å…¥åŠ›ã™ã‚‹ã ã‘ã§ã€ãã®åˆ†é‡ã®å°‚é–€çš„ãªå›ç­”ãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚

### ğŸ”§ ä½¿ã„æ–¹
1. **å°‚é–€å®¶ã‚’é¸æŠ**: ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã‹ã‚‰ç›¸è«‡ã—ãŸã„å°‚é–€å®¶ã‚’é¸ã‚“ã§ãã ã•ã„
2. **è³ªå•ã‚’å…¥åŠ›**: ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã«è³ªå•ã‚„ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„
3. **å›ç­”ã‚’ç¢ºèª**: ã€Œé€ä¿¡ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ã€AIã‹ã‚‰ã®å›ç­”ãŒè¡¨ç¤ºã•ã‚Œã¾ã™

---
""")

# å°‚é–€å®¶ã®é¸æŠï¼ˆãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ï¼‰
expert_type = st.radio(
    "å°‚é–€å®¶ã‚’é¸æŠã—ã¦ãã ã•ã„:",
    options=list(EXPERT_TYPES.keys()),
    index=0
)

# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
user_input = st.text_area(
    "è³ªå•ãƒ»ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:",
    height=150,
    placeholder="ã“ã“ã«è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."
)

# é€ä¿¡ãƒœã‚¿ãƒ³
if st.button("é€ä¿¡", type="primary"):
    if user_input.strip():
        with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
            try:
                # LLMã‹ã‚‰å›ç­”ã‚’å–å¾—
                response = get_llm_response(user_input, expert_type)
                
                # å›ç­”ã‚’è¡¨ç¤º
                st.success("âœ… å›ç­”ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ")
                st.markdown(f"**é¸æŠã•ã‚ŒãŸå°‚é–€å®¶:** {expert_type}")
                st.markdown("---")
                st.markdown("### ğŸ’¡ å›ç­”")
                st.write(response)
                
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    else:
        st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")